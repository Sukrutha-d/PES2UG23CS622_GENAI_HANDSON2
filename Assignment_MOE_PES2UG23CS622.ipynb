{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "print(\"Name: Sukrutha D\")\n",
        "print(\"SRN: PES2UG23CS622\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "230u57eXlRzM",
        "outputId": "464c4e5d-b799-4c90-9472-b5639b94b065"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Sukrutha D\n",
            "SRN: PES2UG23CS622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Unit 2 Assignment: Building a Mixture of Experts (MoE) Router**"
      ],
      "metadata": {
        "id": "Wc_ejtsVlcPe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GjmMuW0jS4q",
        "outputId": "bfa2d23f-39a3-421b-92c3-a0476dadb201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-1.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Downloading groq-1.0.0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install groq python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\".env\", \"w\") as f:\n",
        "    f.write(\"GROQ_API_KEY=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\")"
      ],
      "metadata": {
        "id": "ppc0QznSjv3U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from groq import Groq\n",
        "load_dotenv()\n",
        "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "BASE_MODEL = \"llama-3.1-8b-instant\"\n",
        "\n",
        "print(\"Groq client initialized successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWLHibbwkREi",
        "outputId": "736bc38b-62c4-4df5-c41f-68922bc688df"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Groq client initialized successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_CONFIG = {\n",
        "    \"technical\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are a Technical Support Expert.\n",
        "Be precise, logical, and code-focused.\n",
        "If debugging, explain the root cause and provide corrected code.\n",
        "Avoid unnecessary politeness. Be direct and structured.\n",
        "\"\"\"\n",
        "    },\n",
        "    \"billing\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are a Billing Support Expert.\n",
        "Be empathetic, polite, and policy-driven.\n",
        "Clearly explain refund rules, subscription policies, and next steps.\n",
        "Always reassure the customer.\n",
        "\"\"\"\n",
        "    },\n",
        "    \"general\": {\n",
        "        \"system_prompt\": \"\"\"\n",
        "You are a General Customer Support Assistant.\n",
        "Handle casual conversation and general queries politely and helpfully.\n",
        "\"\"\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "MKhFjM__kUpN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def route_prompt(user_input: str) -> str:\n",
        "    \"\"\"\n",
        "    Classifies query into:\n",
        "    technical, billing, general\n",
        "    Returns ONLY category name.\n",
        "    \"\"\"\n",
        "\n",
        "    routing_prompt = f\"\"\"\n",
        "Classify this text into one of these categories:\n",
        "[technical, billing, general]\n",
        "\n",
        "Return ONLY the category word.\n",
        "\n",
        "Text:\n",
        "{user_input}\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=BASE_MODEL,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a strict text classifier.\"},\n",
        "            {\"role\": \"user\", \"content\": routing_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip().lower()"
      ],
      "metadata": {
        "id": "1EnX1ucDkX9t"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Orchestrator Function**"
      ],
      "metadata": {
        "id": "-VBYfv5Glu9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_request(user_input: str) -> str:\n",
        "    category = route_prompt(user_input)\n",
        "    print(f\"[Router Selected]: {category}\")\n",
        "\n",
        "    if category not in MODEL_CONFIG:\n",
        "        category = \"general\"\n",
        "\n",
        "    system_prompt = MODEL_CONFIG[category][\"system_prompt\"]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=BASE_MODEL,\n",
        "        temperature=0.7,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "0jbObJvekb0G"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing Technical Query **"
      ],
      "metadata": {
        "id": "iyhKEnLxmQZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"My python script is throwing an IndexError on line 5.\"\n",
        "response = process_request(query)\n",
        "\n",
        "print(\"\\nExpert Response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMnz5AKfkhUK",
        "outputId": "19d6bced-8900-46d3-f0e9-35db8a9fe453"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Router Selected]: technical\n",
            "\n",
            "Expert Response:\n",
            "\n",
            "To troubleshoot the issue, I'll need more information. Please provide the following:\n",
            "\n",
            "1. The line numbers of your Python script (not line numbers starting from 1, but actual line numbers).\n",
            "2. The code snippet where the error occurs.\n",
            "3. The full error message, including the stack trace.\n",
            "\n",
            "Once I have this information, I can help you identify the root cause and provide the necessary corrections.\n",
            "\n",
            "If you cannot provide the exact line numbers, please paste the entire code snippet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing Billing Query**"
      ],
      "metadata": {
        "id": "CZhfIjGRmpHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"I was charged twice for my subscription this month.\"\n",
        "response = process_request(query)\n",
        "\n",
        "print(\"\\nExpert Response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohE0Xxzik3y0",
        "outputId": "f7d4de54-06a5-48d1-b25e-8ec577179d8e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Router Selected]: billing\n",
            "\n",
            "Expert Response:\n",
            "\n",
            "I'm so sorry to hear that you've been charged twice for your subscription. I'm here to help and make things right. Can you please confirm your account information, including your name and the date of the charges, so I can look into this further?\n",
            "\n",
            "In terms of our refund policy, I'd like to clarify that we offer a refund for duplicate or incorrect charges. If we find that the charges were indeed errors on our part, we'll process a refund as soon as possible.\n",
            "\n",
            "However, if the charges were due to a change in your subscription plan or billing cycle, our standard refund policy may apply. This policy states that we don't offer refunds for subscription charges, but we do offer a prorated refund for prepaid plans.\n",
            "\n",
            "Let's review your account and determine the best course of action. In the meantime, I can offer you a temporary credit on your account, which will be applied to your next payment. This way, you won't be charged again for the duplicate amount.\n",
            "\n",
            "Please be assured that I'm committed to resolving this issue for you as quickly as possible. Can I proceed with reviewing your account and finding a solution?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bonus Challenge**"
      ],
      "metadata": {
        "id": "3lFP37HXlLT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bitcoin_price():\n",
        "    return \"$63,450 (Mock Price)\""
      ],
      "metadata": {
        "id": "5a7IZ11vk427"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def route_prompt(user_input: str) -> str:\n",
        "\n",
        "    routing_prompt = f\"\"\"\n",
        "Classify this text into one of these categories:\n",
        "[technical, billing, general, crypto]\n",
        "\n",
        "Return ONLY the category word.\n",
        "\n",
        "Text:\n",
        "{user_input}\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=BASE_MODEL,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a strict text classifier.\"},\n",
        "            {\"role\": \"user\", \"content\": routing_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip().lower()"
      ],
      "metadata": {
        "id": "4MkLZXaWk836"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_request(user_input: str) -> str:\n",
        "    category = route_prompt(user_input)\n",
        "    print(f\"[Router Selected]: {category}\")\n",
        "\n",
        "    if category == \"crypto\":\n",
        "        return f\"The current price of Bitcoin is {get_bitcoin_price()}\"\n",
        "\n",
        "    if category not in MODEL_CONFIG:\n",
        "        category = \"general\"\n",
        "\n",
        "    system_prompt = MODEL_CONFIG[category][\"system_prompt\"]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=BASE_MODEL,\n",
        "        temperature=0.7,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "Eh3dZbnfk81H"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the current price of Bitcoin?\"\n",
        "response = process_request(query)\n",
        "\n",
        "print(\"\\nExpert Response:\\n\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GfDbzP6lEMA",
        "outputId": "75d3e54a-8b9e-4da9-d0c1-eda2aa880fdd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Router Selected]: crypto\n",
            "\n",
            "Expert Response:\n",
            "\n",
            "The current price of Bitcoin is $63,450 (Mock Price)\n"
          ]
        }
      ]
    }
  ]
}