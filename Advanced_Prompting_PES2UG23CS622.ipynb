{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzb6Qf3FCWkr",
        "outputId": "976dabc2-8688-4ce7-f061-d57b4ab5ca14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: SUKRUTHA D\n",
            "SRN: PES2UG23CS622\n"
          ]
        }
      ],
      "source": [
        "print(\"Name: SUKRUTHA D\")\n",
        "print(\"SRN: PES2UG23CS622\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3a: Chain of Thought (CoT)**"
      ],
      "metadata": {
        "id": "4e5QBtLlCfVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install python-dotenv --upgrade --quiet langchain langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt4avIloCl1i",
        "outputId": "fbce43d0-1edd-437a-b75e-302a4ee05e88"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/137.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.5/500.5 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.1/158.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")\n",
        "\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.0)\n"
      ],
      "metadata": {
        "id": "VgBEugKdCt2y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many does he have now?\"\n",
        "\n",
        "\n",
        "prompt_standard = f\"Answer this question: {question}\"\n",
        "print(\"--- STANDARD (Llama3.1-8b) ---\")\n",
        "print(llm.invoke(prompt_standard).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzB30RyDDieD",
        "outputId": "2ebd287e-a7f4-42b2-8e94-7702d575f41f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STANDARD (Llama3.1-8b) ---\n",
            "To find out how many tennis balls Roger has now, we need to add the initial number of tennis balls he had (5) to the number of tennis balls he bought (2 cans * 3 tennis balls per can).\n",
            "\n",
            "2 cans * 3 tennis balls per can = 6 tennis balls\n",
            "\n",
            "Now, let's add the initial number of tennis balls (5) to the number of tennis balls he bought (6):\n",
            "\n",
            "5 + 6 = 11\n",
            "\n",
            "So, Roger now has 11 tennis balls.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_cot = f\"Answer this question. Let's think step by step. {question}\"\n",
        "\n",
        "print(\"--- Chain of Thought (Llama3.1-8b) ---\")\n",
        "print(llm.invoke(prompt_cot).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k65JeY30Dncr",
        "outputId": "1e1a8ab9-cac1-41f8-f558-41311b3ff207"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Chain of Thought (Llama3.1-8b) ---\n",
            "To find out how many tennis balls Roger has now, we need to follow these steps:\n",
            "\n",
            "1. Roger already has 5 tennis balls.\n",
            "2. He buys 2 more cans of tennis balls. Each can has 3 tennis balls, so he buys 2 x 3 = 6 more tennis balls.\n",
            "3. Now, we add the tennis balls he already had (5) to the new tennis balls he bought (6). 5 + 6 = 11\n",
            "\n",
            "So, Roger now has 11 tennis balls.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3b: Tree of Thoughts (ToT) & Graph of Thoughts(GoT)**"
      ],
      "metadata": {
        "id": "JpSaEudCDtOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")\n",
        "\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.7)\n"
      ],
      "metadata": {
        "id": "vIPTwcFXD2n-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tree Of Thoughts\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "problem = \"How can I get my 5-year-old to eat vegetables?\"\n",
        "\n",
        "prompt_branch = ChatPromptTemplate.from_template(\n",
        "    \"Problem: {problem}. Give me one unique, creative solution. Solution {id}:\"\n",
        ")\n",
        "\n",
        "branches = RunnableParallel(\n",
        "    sol1=prompt_branch.partial(id=\"1\") | llm | StrOutputParser(),\n",
        "    sol2=prompt_branch.partial(id=\"2\") | llm | StrOutputParser(),\n",
        "    sol3=prompt_branch.partial(id=\"3\") | llm | StrOutputParser(),\n",
        ")\n",
        "\n",
        "prompt_judge = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    I have three proposed solutions for: '{problem}'\n",
        "\n",
        "    1: {sol1}\n",
        "    2: {sol2}\n",
        "    3: {sol3}\n",
        "\n",
        "    Act as a Child Psychologist. Pick the most sustainable one (not bribery) and explain why.\n",
        "    \"\"\"\n",
        ")\n",
        "tot_chain = (\n",
        "    RunnableParallel(problem=RunnableLambda(lambda x: x), branches=branches)\n",
        "    | (lambda x: {**x[\"branches\"], \"problem\": x[\"problem\"]})\n",
        "    | prompt_judge\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "print(\"--- Tree of Thoughts (ToT) Result ---\")\n",
        "print(tot_chain.invoke(problem))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6dt53PVD_Cx",
        "outputId": "1743e962-6681-4c06-e8bd-d2bfec6550e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tree of Thoughts (ToT) Result ---\n",
            "After reviewing the three proposed solutions, I would recommend Solution 2: Make it a Game or a Challenge as the most sustainable option. Here's why:\n",
            "\n",
            "1. **Encourages exploration, not just consumption**: By turning mealtime into a game or challenge, you're encouraging your child to explore new vegetables in a fun and interactive way. This approach focuses on the process of trying new foods, rather than just consuming them.\n",
            "\n",
            "2. **Develops problem-solving skills**: Games and challenges require children to think critically and come up with solutions. In this case, they'll need to figure out which vegetables to try, and how to approach them.\n",
            "\n",
            "3. **Builds confidence and self-efficacy**: As your child successfully tries new vegetables and completes challenges, they'll develop a sense of confidence and self-efficacy. This will help them feel more empowered to make healthy choices.\n",
            "\n",
            "4. **Long-term benefits**: Unlike the \"Veggie Face\" approach, which might become less engaging as your child gets older, games and challenges can be adapted to different age groups and interests. This makes them a more sustainable solution for the long term.\n",
            "\n",
            "5. **Fosters a growth mindset**: By framing mealtime as a game or challenge, you're promoting a growth mindset in your child. They'll learn to view trying new foods as an opportunity for growth and learning, rather than a source of stress or anxiety.\n",
            "\n",
            "6. **Reduces the risk of bribery**: Solution 2 avoids the risk of bribery, which can undermine the development of healthy eating habits in the long run. By making mealtime a positive and engaging experience, you'll encourage your child to make healthy choices without relying on rewards or punishments.\n",
            "\n",
            "Overall, Solution 2: Make it a Game or a Challenge offers a sustainable and engaging approach to encouraging your child to try new vegetables. It develops problem-solving skills, builds confidence, and fosters a growth mindset, making it an excellent choice for promoting healthy eating habits.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Graph of Thoughts(GoT)\n",
        "prompt_draft = ChatPromptTemplate.from_template(\n",
        "    \"Write a 1-sentence movie plot about: {topic}. Genre: {genre}.\"\n",
        ")\n",
        "\n",
        "drafts = RunnableParallel(\n",
        "    draft_scifi=prompt_draft.partial(genre=\"Sci-Fi\") | llm | StrOutputParser(),\n",
        "    draft_romance=prompt_draft.partial(genre=\"Romance\") | llm | StrOutputParser(),\n",
        "    draft_horror=prompt_draft.partial(genre=\"Horror\") | llm | StrOutputParser(),\n",
        ")\n",
        "\n",
        "prompt_combine = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    I have three movie ideas for the topic '{topic}':\n",
        "    1. Sci-Fi: {draft_scifi}\n",
        "    2. Romance: {draft_romance}\n",
        "    3. Horror: {draft_horror}\n",
        "\n",
        "    Your task: Create a new Mega-Movie that combines the TECHNOLOGY of Sci-Fi, the PASSION of Romance, and the FEAR of Horror.\n",
        "    Write one paragraph.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "got_chain = (\n",
        "    RunnableParallel(topic=RunnableLambda(lambda x: x), drafts=drafts)\n",
        "    | (lambda x: {**x[\"drafts\"], \"topic\": x[\"topic\"]})\n",
        "    | prompt_combine\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "print(\"--- Graph of Thoughts (GoT) Result ---\")\n",
        "print(got_chain.invoke(\"Time Travel\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j88drcFaEMbR",
        "outputId": "6b0ddcef-89c0-4034-8743-62b3c62dc728"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Graph of Thoughts (GoT) Result ---\n",
            "In the mind-bending thriller, \"Chrono Labyrinth,\" a brilliant scientist, Emma, discovers a way to manipulate the space-time continuum using a revolutionary technology that allows her to travel through the fabric of time. As she experiments with this power, she finds herself falling deeply in love with a younger version of her current boyfriend, Jack, whom she encounters during her time travels. However, their idyllic romance is disrupted when Emma realizes that each time she tries to alter their past, the consequences become increasingly terrifying: every time she changes something, a dark and twisted version of Jack emerges, forcing Emma to fight for control of her own reality and confront the evil doppelganger that threatens to destroy her life. As the stakes escalate and the labyrinthine timelines begin to collapse, Emma must navigate the treacherous landscape of time to find a way to restore the original timeline and save the love of her life.\n"
          ]
        }
      ]
    }
  ]
}